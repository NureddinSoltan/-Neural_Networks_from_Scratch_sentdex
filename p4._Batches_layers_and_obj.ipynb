{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why batch?\n",
    "- we can calculate these things in parallel.\n",
    "  - The bigger the batch the more parallel operations that we can run.\n",
    "- It helps with generalization.\n",
    "###### Note: We tend to do neural networks on GPU instead of CPU.\n",
    "\n",
    "<div style=\"display: inline-flex; align-items: center;\">\n",
    "  <!-- Video Thumbnail -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=s164HyJuL94\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://img.youtube.com/vi/s164HyJuL94/0.jpg\" style=\"width: 100%; display: block;\">\n",
    "  </a>\n",
    "\n",
    "  <!-- Play Button -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=s164HyJuL94\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/YouTube_play_button_icon_%282013%E2%80%932017%29.svg\" \n",
    "         style=\"width: 50px; height: auto; margin-left: 5px;\">\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the Matrix Product works?\n",
    "\n",
    "<div style=\"display: inline-flex; align-items: center;\">\n",
    "  <!-- Video Thumbnail -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=KBPvlUp-m5Y\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://img.youtube.com/vi/KBPvlUp-m5Y/0.jpg\" style=\"width: 100%; display: block;\">\n",
    "  </a>\n",
    "\n",
    "  <!-- Play Button -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=KBPvlUp-m5Y\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/YouTube_play_button_icon_%282013%E2%80%932017%29.svg\" \n",
    "         style=\"width: 50px; height: auto; margin-left: 5px;\">\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m weights \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m],\n\u001b[1;32m      8\u001b[0m \t\t\t[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.91\u001b[39m, \u001b[38;5;241m0.26\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m],\n\u001b[1;32m      9\u001b[0m \t\t\t[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.26\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.27\u001b[39m, \u001b[38;5;241m0.17\u001b[39m, \u001b[38;5;241m0.87\u001b[39m]]\n\u001b[1;32m     10\u001b[0m biases \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m biases\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "\t\t\t[2.0, 5.0, -1.0, 2.0],\n",
    "            [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "\t\t\t[0.5, -0.91, 0.26, -0.5],\n",
    "\t\t\t[-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "output = np.dot(weights, inputs) + biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we got this error because it makes sense.\n",
    "\n",
    "we got first row in **`inputs`** by first column in **`wights`**.\n",
    "\n",
    "#### So to solve this we will use **Transpose**\n",
    "**Transpose:** just swap rows and columns.\n",
    "\n",
    "<div style=\"display: inline-flex; align-items: center;\">\n",
    "  <!-- Video Thumbnail -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=ZN60jdWk8aM\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://img.youtube.com/vi/ZN60jdWk8aM/0.jpg\" style=\"width: 100%; display: block;\">\n",
    "  </a>\n",
    "\n",
    "  <!-- Play Button -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=ZN60jdWk8aM\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/YouTube_play_button_icon_%282013%E2%80%932017%29.svg\" \n",
    "         style=\"width: 50px; height: auto; margin-left: 5px;\">\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "\t\t\t[2.0, 5.0, -1.0, 2.0],\n",
    "            [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "\t\t\t[0.5, -0.91, 0.26, -0.5],\n",
    "\t\t\t[-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "output = np.dot(inputs, np.array(weights).T) + biases\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why using **Transpose**? and why **Weights** become on the right? \n",
    "\n",
    "all of these things explained here\n",
    "\n",
    "<div style=\"display: inline-flex; align-items: center;\">\n",
    "  <!-- Video Thumbnail -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=2c9CJ_7YT8w\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://img.youtube.com/vi/2c9CJ_7YT8w/0.jpg\" style=\"width: 100%; display: block;\">\n",
    "  </a>\n",
    "\n",
    "  <!-- Play Button -->\n",
    "  <a href=\"https://www.youtube.com/watch?v=2c9CJ_7YT8w\" target=\"_blank\" style=\"display: inline-block;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/YouTube_play_button_icon_%282013%E2%80%932017%29.svg\" \n",
    "         style=\"width: 50px; height: auto; margin-left: 5px;\">\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "# We're gonna add another layer:\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "\t\t\t[2.0, 5.0, -1.0, 2.0],\n",
    "            [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "\t\t\t[0.5, -0.91, 0.26, -0.5],\n",
    "\t\t\t[-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "\t\t\t[-0.5, 0.12, -0.33],\n",
    "\t\t\t[-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can convert this layers to objects instead of written it like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
      " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
      " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
      "-------------------\n",
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = [[1, 2, 3, 2.5],\n",
    "\t[2.0, 5.0, -1.0, 2.0],\n",
    "\t[-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons) # # randn gaussian distribution bounded around zero.\n",
    "        self.biases = np.zeros((1, n_neurons)) # np.zeros is generating a zeros\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "layer1 = Layer_Dense(4,5)\n",
    "layer2 = Layer_Dense(5,2)\n",
    "\n",
    "layer1.forward(X)\n",
    "print(layer1.output)\n",
    "print(\"-------------------\")\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ChatGPT for a clear explanation:\n",
    "Let's break down how the output shape `(3, 5)` is determined when you call `layer1.forward(X)`.\n",
    "\n",
    "1. **Input Matrix (`X`)**:\n",
    "   - `X` is the input matrix with shape `(3, 4)`.\n",
    "   - This shape represents 3 samples (rows) and 4 features (columns).\n",
    "\n",
    "   ```python\n",
    "   X = [[1, 2, 3, 2.5],\n",
    "        [2.0, 5.0, -1.0, 2.0],\n",
    "        [-1.5, 2.7, 3.3, -0.8]]\n",
    "   ```\n",
    "   \n",
    "2. **Weights Matrix (`self.weights`)**:\n",
    "   - `self.weights` is initialized with shape `(4, 5)`, meaning each of the 4 input features will connect to each of the 5 neurons in this layer.\n",
    "   - The weights matrix shape `(4, 5)` is created based on `n_inputs=4` and `n_neurons=5`.\n",
    "\n",
    "3. **Dot Product Operation**:\n",
    "   - In the `forward` method, the output is calculated using:\n",
    "     ```python\n",
    "     self.output = np.dot(inputs, self.weights) + self.biases\n",
    "     ```\n",
    "   - Here, `np.dot(inputs, self.weights)` computes the dot product between `X` (shape `(3, 4)`) and `self.weights` (shape `(4, 5)`).\n",
    "\n",
    "4. **Matrix Multiplication Shape Rules**:\n",
    "   - When you multiply two matrices, the rule is that the **number of columns of the first matrix** must equal the **number of rows of the second matrix**.\n",
    "   - Since `X` has 4 columns (features) and `self.weights` has 4 rows, this multiplication is valid.\n",
    "   - The resulting shape after the dot product is `(3, 5)`:\n",
    "     - **3**: From `X`'s 3 rows (samples).\n",
    "     - **5**: From `self.weights`'s 5 columns (neurons).\n",
    "\n",
    "5. **Adding Biases**:\n",
    "   - The biases, which have shape `(1, 5)`, are added to each row of the resulting `(3, 5)` matrix from the dot product, keeping the final shape `(3, 5)`.\n",
    "\n",
    "### Final Output Shape\n",
    "So, `layer1.output` has shape `(3, 5)`, which means:\n",
    "- There are **3 samples** in the output (one for each input sample in `X`).\n",
    "- Each sample has **5 values**, representing the output from each of the 5 neurons in `layer1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01549474  0.03781625 -0.08877857 -0.19807965 -0.03479121]\n",
      " [ 0.0156349   0.12302907  0.12023798 -0.03873268 -0.03023028]\n",
      " [-0.1048553  -0.14200179 -0.17062702  0.19507754 -0.05096522]\n",
      " [-0.04380743 -0.12527954  0.07774904 -0.16138978 -0.02127403]]\n"
     ]
    }
   ],
   "source": [
    "print(0.10 * np.random.randn(4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17640523  0.04001572  0.0978738   0.22408932  0.1867558 ]\n",
      " [-0.09772779  0.09500884 -0.01513572 -0.01032189  0.04105985]\n",
      " [ 0.01440436  0.14542735  0.07610377  0.0121675   0.04438632]\n",
      " [ 0.03336743  0.14940791 -0.02051583  0.03130677 -0.08540957]]\n"
     ]
    }
   ],
   "source": [
    "koko= (layer1.weights)+layer1.biases\n",
    "print(koko)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
